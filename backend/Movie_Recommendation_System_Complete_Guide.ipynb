{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GZp5ZWzWyUXE"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from ast import literal_eval\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z_SmfY9WfBXk"
      },
      "outputs": [],
      "source": [
        "def get_director(x):\n",
        "    \"\"\"\n",
        "    Extract the Name of the Director for a movie if it is present inside the job\n",
        "    \"\"\"\n",
        "    for i in x:\n",
        "        if i['job'] == 'Director':\n",
        "            return i['name']\n",
        "    return np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6ZDrGO9oyUUs"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'backend/assets/content/datamovies_metadata.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m movies_dataset  \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackend/assets/content/datamovies_metadata.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m credits         \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend/assets/content/datacredits.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m keywords        \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend/assets/content/datakeywords.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32me:\\ROOTDIR\\Conda\\envs\\gpu_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\ROOTDIR\\Conda\\envs\\gpu_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32me:\\ROOTDIR\\Conda\\envs\\gpu_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\ROOTDIR\\Conda\\envs\\gpu_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32me:\\ROOTDIR\\Conda\\envs\\gpu_env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'backend/assets/content/datamovies_metadata.csv'"
          ]
        }
      ],
      "source": [
        "movies_dataset  = pd.read_csv('backend/assets/content/datamovies_metadata.csv')\n",
        "credits         = pd.read_csv('backend/assets/content/datacredits.csv')\n",
        "keywords        = pd.read_csv('backend/assets/content/datakeywords.csv')\n",
        "links           = pd.read_csv('backend/assets/content/datalinks.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2ruYT_8N_Cw6"
      },
      "outputs": [],
      "source": [
        "## Dropping these 3 rows because Date Column value for them is string date instead of Int with ID.\n",
        "movies_dataset = movies_dataset.drop([19730, 29503, 35587])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g8DNnxq4yUS_"
      },
      "outputs": [],
      "source": [
        "## Extracting Genres of movies from the genres dictionary. If not present, append empty list\n",
        "movies_dataset['genres'] = movies_dataset['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rrLCuGdT2xo3"
      },
      "outputs": [],
      "source": [
        "## Convert to common data type for primary key in our dataset\n",
        "keywords['id'] = keywords['id'].astype('int')\n",
        "credits['id'] = credits['id'].astype('int')\n",
        "movies_dataset['id'] = movies_dataset['id'].astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kCZEqojC2xm9"
      },
      "outputs": [],
      "source": [
        "## Merging movies dataset with credits & keywords to form master dataset\n",
        "movies_dataset = movies_dataset.merge(credits, on='id')\n",
        "master_dataset = movies_dataset.merge(keywords, on='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "Vb-6uHBCV0Cp",
        "outputId": "f254cdae-1e02-4907-ee0f-7cf61b04599c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>adult</th>\n",
              "      <th>belongs_to_collection</th>\n",
              "      <th>budget</th>\n",
              "      <th>genres</th>\n",
              "      <th>homepage</th>\n",
              "      <th>id</th>\n",
              "      <th>imdb_id</th>\n",
              "      <th>original_language</th>\n",
              "      <th>original_title</th>\n",
              "      <th>overview</th>\n",
              "      <th>...</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>status</th>\n",
              "      <th>tagline</th>\n",
              "      <th>title</th>\n",
              "      <th>video</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>vote_count</th>\n",
              "      <th>cast</th>\n",
              "      <th>crew</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
              "      <td>30000000</td>\n",
              "      <td>[Animation, Comedy, Family]</td>\n",
              "      <td>http://toystory.disney.com/toy-story</td>\n",
              "      <td>862</td>\n",
              "      <td>tt0114709</td>\n",
              "      <td>en</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>False</td>\n",
              "      <td>7.7</td>\n",
              "      <td>5415.0</td>\n",
              "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
              "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
              "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65000000</td>\n",
              "      <td>[Adventure, Fantasy, Family]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8844</td>\n",
              "      <td>tt0113497</td>\n",
              "      <td>en</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>When siblings Judy and Peter discover an encha...</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
              "      <td>Released</td>\n",
              "      <td>Roll the dice and unleash the excitement!</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>False</td>\n",
              "      <td>6.9</td>\n",
              "      <td>2413.0</td>\n",
              "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
              "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
              "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   adult                              belongs_to_collection    budget  \\\n",
              "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
              "1  False                                                NaN  65000000   \n",
              "\n",
              "                         genres                              homepage    id  \\\n",
              "0   [Animation, Comedy, Family]  http://toystory.disney.com/toy-story   862   \n",
              "1  [Adventure, Fantasy, Family]                                   NaN  8844   \n",
              "\n",
              "     imdb_id original_language original_title  \\\n",
              "0  tt0114709                en      Toy Story   \n",
              "1  tt0113497                en        Jumanji   \n",
              "\n",
              "                                            overview  ...  \\\n",
              "0  Led by Woody, Andy's toys live happily in his ...  ...   \n",
              "1  When siblings Judy and Peter discover an encha...  ...   \n",
              "\n",
              "                                    spoken_languages    status  \\\n",
              "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
              "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
              "\n",
              "                                     tagline      title  video  vote_average  \\\n",
              "0                                        NaN  Toy Story  False           7.7   \n",
              "1  Roll the dice and unleash the excitement!    Jumanji  False           6.9   \n",
              "\n",
              "   vote_count                                               cast  \\\n",
              "0      5415.0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
              "1      2413.0  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
              "\n",
              "                                                crew  \\\n",
              "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   \n",
              "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   \n",
              "\n",
              "                                            keywords  \n",
              "0  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...  \n",
              "1  [{'id': 10090, 'name': 'board game'}, {'id': 1...  \n",
              "\n",
              "[2 rows x 27 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "master_dataset.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbSAFU9X-vGh",
        "outputId": "d193275d-a2cb-4644-8c84-c19cd7dfa599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
            "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
            "       'popularity', 'poster_path', 'production_companies',\n",
            "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
            "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
            "       'vote_average', 'vote_count', 'cast', 'crew', 'keywords'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(master_dataset.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yw0oWEY2xk3",
        "outputId": "dd5ce026-ba2a-4acc-a6cd-ef59917d2073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(46628, 27)\n"
          ]
        }
      ],
      "source": [
        "links = links[links['tmdbId'].notnull()]['tmdbId'].astype('int')\n",
        "master_dataset = master_dataset[master_dataset['id'].isin(links)]\n",
        "print(master_dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gJYGvLA_2xis"
      },
      "outputs": [],
      "source": [
        "## Updating cast, crew and keyword columns by parsing them as their loaded data type is string but need to be converted to list\n",
        "master_dataset['cast']      = master_dataset['cast'].apply(literal_eval)\n",
        "master_dataset['crew']      = master_dataset['crew'].apply(literal_eval)\n",
        "master_dataset['keywords']  = master_dataset['keywords'].apply(literal_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MTXcRtg72xgX"
      },
      "outputs": [],
      "source": [
        "## Updating cast to maintain proportion between different lengths (keeping top 3 cast members)\n",
        "master_dataset['cast']      = master_dataset['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
        "master_dataset['cast']      = master_dataset['cast'].apply(lambda x: x[:3] if len(x) >=3 else x)\n",
        "\n",
        "## Setting keywords to empty list if does not exists, otherwise taking into account for each word as keyword\n",
        "master_dataset['keywords']  = master_dataset['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
        "\n",
        "## Extracting directory names from the crew\n",
        "master_dataset['director']  = master_dataset['crew'].apply(get_director)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Jaqq7Wwk-E2-"
      },
      "outputs": [],
      "source": [
        "## for uniqueness, removing all the spaces in between the names\n",
        "master_dataset['cast']          = master_dataset['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
        "\n",
        "## Maintaining the original director name as main director\n",
        "master_dataset['main_director'] = master_dataset['director']\n",
        "\n",
        "## Maintaining the number of director to maintain proportion (similar to cast column above)\n",
        "master_dataset['director']      = master_dataset['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
        "master_dataset['director']      = master_dataset['director'].apply(lambda x: [x,x,x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKR9dFAL-G63",
        "outputId": "df7658b3-6519-42df-f8b9-a9f58bc2219a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keyword\n",
            "woman director      3128\n",
            "independent film    1942\n",
            "murder              1314\n",
            "based on novel       841\n",
            "musical              734\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## Stacking the keywords and keeping the movies which containers X number of keywords as minimum\n",
        "s = master_dataset.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\n",
        "s.name = 'keyword'\n",
        "s = s.value_counts()\n",
        "print(s[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jN2OJj8H-I-V"
      },
      "outputs": [],
      "source": [
        "## Will try to map where more than 1 keyword is present for the movie\n",
        "s = s[s > 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "j3lSxkmC-N-h"
      },
      "outputs": [],
      "source": [
        "## creating an object for ENGLISH Stemmer - Snowball to trim down keywords to their stem words\n",
        "stemmer                     = SnowballStemmer('english')\n",
        "\n",
        "## Trim down keywords to their stem words and then remove the space between keywords which are having more than 1 length for uniqueness\n",
        "master_dataset['keywords']  = master_dataset['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
        "master_dataset['keywords']  = master_dataset['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        [jealousi, toy, boy, friendship, friend, rival...\n",
              "1        [boardgam, disappear, basedonchildren'sbook, n...\n",
              "2              [fish, bestfriend, duringcreditsst, oldmen]\n",
              "3        [basedonnovel, interracialrelationship, single...\n",
              "4        [babi, midlifecrisi, confid, age, daughter, mo...\n",
              "                               ...                        \n",
              "46623                                          [tragiclov]\n",
              "46624                                [artist, play, pinoy]\n",
              "46625                                                   []\n",
              "46626                                                   []\n",
              "46627                                                   []\n",
              "Name: keywords, Length: 46628, dtype: object"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemmer                     = SnowballStemmer('english')\n",
        "master_dataset['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n-PuVspO2fI",
        "outputId": "80b12c89-967f-45cd-ff2f-4a3b7cd9b736"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [jealousi, toy, boy, friendship, friend, rival...\n",
              "1    [boardgam, disappear, basedonchildren'sbook, n...\n",
              "2       [fish, bestfriend, duringcreditssting, oldmen]\n",
              "Name: keywords, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "master_dataset['keywords'].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uSncyfonOyvC"
      },
      "outputs": [],
      "source": [
        "## Creating a soup feature - combination of (keywords, cast, director, genres)\n",
        "master_dataset['soup'] = master_dataset['keywords'] + master_dataset['cast'] + master_dataset['director'] + master_dataset['genres']\n",
        "\n",
        "## Modifying by placing single space between all the soup words\n",
        "master_dataset['soup'] = master_dataset['soup'].apply(lambda x: ' '.join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kIbzUnHPBBD",
        "outputId": "8020f807-2c6e-4118-c85b-c290afc484d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    jealousi toy boy friendship friend rivalri boy...\n",
              "1    boardgam disappear basedonchildren'sbook newho...\n",
              "2    fish bestfriend duringcreditssting oldmen walt...\n",
              "Name: soup, dtype: object"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "master_dataset['soup'].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LaAIqSo-chN",
        "outputId": "eb933be4-fc0c-4c25-d9f1-d6592de4f0de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
            "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
            "       'popularity', 'poster_path', 'production_companies',\n",
            "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
            "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
            "       'vote_average', 'vote_count', 'cast', 'crew', 'keywords', 'director',\n",
            "       'main_director', 'soup'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(master_dataset.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GfmKSQ3f-d0e"
      },
      "outputs": [],
      "source": [
        "## Removing unwanted columns from the dataset - these features can be used if you wish to add more features to your recommender system.\n",
        "## We are not going to use them, so we are removing them.\n",
        "master_dataset.drop(['adult', 'belongs_to_collection', 'budget','homepage','original_language', 'production_companies','production_countries', 'revenue', 'runtime','spoken_languages','status','video'],axis=1,inplace=True)\n",
        "master_dataset.drop(['overview', 'tagline','vote_average', 'vote_count', 'cast', 'crew','keywords', 'director'],axis=1,inplace=True)\n",
        "master_dataset.drop(['id','imdb_id','original_title','poster_path','genres'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tTN76P-3QF6Q"
      },
      "outputs": [],
      "source": [
        "## Checking popularity column for being non-float data type and removing them\n",
        "master_dataset['popularity']    = master_dataset.apply(lambda r: r['popularity'] if type(r['popularity'])==float else np.nan, axis=1)\n",
        "master_dataset.dropna(inplace=True)\n",
        "\n",
        "## Checking director column for being non-string data type and removing them\n",
        "master_dataset['main_director'] = master_dataset.apply(lambda r: r['main_director'] if len(r['main_director'])>1 else np.nan, axis=1)\n",
        "master_dataset.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ovSdqYXFPw0x"
      },
      "outputs": [],
      "source": [
        "## Sorting the whole dataset based on popularity. This will help us to take top X number of movies based on popularity.\n",
        "master_dataset.sort_values(by=['popularity'],ascending=False,inplace=True)\n",
        "\n",
        "## Dropping popularity column after sorting based on popularity\n",
        "master_dataset.drop(['popularity'],axis=1,inplace=True)\n",
        "master_dataset.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5t60gsB6Qjh3"
      },
      "outputs": [],
      "source": [
        "## Reset index because after sorting, the index values have changed.\n",
        "master_dataset.reset_index(inplace=True,drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "PaqeTa8DZrEz"
      },
      "outputs": [],
      "source": [
        "## Checking release date column for being non-string data type and removing them\n",
        "master_dataset['release_date'] = master_dataset.apply(lambda r: r['release_date'] if len(r['release_date'])>1 else np.nan, axis=1)\n",
        "master_dataset.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6Vx_CcUnQqLR"
      },
      "outputs": [],
      "source": [
        "master_dataset = master_dataset[:100]\n",
        "\n",
        "## For Demo, we will take top 2500 movies, which is hosted online already.\n",
        "# master_dataset = master_dataset[:2500]\n",
        "\n",
        "## For Tiny-Model, we will take top 1000 movies\n",
        "# master_dataset = master_dataset[:1000]\n",
        "\n",
        "## For Extra-Small-Model, we will take top 5000 movies\n",
        "# master_dataset = master_dataset[:5000]\n",
        "\n",
        "## For Small-Model, we will take top 10000 movies\n",
        "# master_dataset = master_dataset[:10000]\n",
        "\n",
        "## For Medium-Model, we will take top 20000 movies\n",
        "# master_dataset = master_dataset[:20000]\n",
        "\n",
        "## For Large-Model, we will take top 30000 movies\n",
        "# master_dataset = master_dataset[:30000]\n",
        "\n",
        "## LEAVE ALL THE LINES COMMENTED IF YOU WISH TO TRAIN FULL MOVIES DATASET."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpL1QTwOIgH7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XRz17iHZZnRc",
        "outputId": "46d95aef-0fed-425a-94c9-3652495ca57b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>release_date</th>\n",
              "      <th>title</th>\n",
              "      <th>main_director</th>\n",
              "      <th>soup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-06-17</td>\n",
              "      <td>Minions</td>\n",
              "      <td>Kyle Balda</td>\n",
              "      <td>assist aftercreditssting duringcreditssting ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-10-24</td>\n",
              "      <td>Big Hero 6</td>\n",
              "      <td>Chris Williams</td>\n",
              "      <td>brotherbrotherrelationship hero talent reveng ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-02-09</td>\n",
              "      <td>Deadpool</td>\n",
              "      <td>Tim Miller</td>\n",
              "      <td>antihero mercenari marvelcom superhero basedon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-04-19</td>\n",
              "      <td>Guardians of the Galaxy Vol. 2</td>\n",
              "      <td>James Gunn</td>\n",
              "      <td>sequel superhero basedoncom misfit space outer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-12-10</td>\n",
              "      <td>Avatar</td>\n",
              "      <td>James Cameron</td>\n",
              "      <td>cultureclash futur spacewar spacecoloni societ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  release_date                           title   main_director  \\\n",
              "0   2015-06-17                         Minions      Kyle Balda   \n",
              "1   2014-10-24                      Big Hero 6  Chris Williams   \n",
              "2   2016-02-09                        Deadpool      Tim Miller   \n",
              "3   2017-04-19  Guardians of the Galaxy Vol. 2      James Gunn   \n",
              "4   2009-12-10                          Avatar   James Cameron   \n",
              "\n",
              "                                                soup  \n",
              "0  assist aftercreditssting duringcreditssting ev...  \n",
              "1  brotherbrotherrelationship hero talent reveng ...  \n",
              "2  antihero mercenari marvelcom superhero basedon...  \n",
              "3  sequel superhero basedoncom misfit space outer...  \n",
              "4  cultureclash futur spacewar spacecoloni societ...  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## This is our final dataset which we will be using for training our word and cosine similarity matrix\n",
        "master_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB09EkGsHK7c",
        "outputId": "3963b746-ca89-4761-a6b8-8b575ec47039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 4)\n"
          ]
        }
      ],
      "source": [
        "print(master_dataset.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brYr66w7GO_M"
      },
      "source": [
        "## Recommendation Matrix\n",
        "\n",
        ">     Building the matrix which contains similarity scores between movies based on the features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu_PsFWFJH_l"
      },
      "source": [
        "#### 1: Training Word based count vectorizer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "73hkdAZWAJ76"
      },
      "outputs": [],
      "source": [
        "## Creating a Count Vectorizer object which will be based on word analyzer, with ngram 1-2 and minimum number of occurances of words as 2\n",
        "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=2, stop_words='english')\n",
        "\n",
        "## Adjusting the count vectorizer object with respect to our dataset\n",
        "count_matrix = count.fit_transform(master_dataset['soup'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V98dZQmkAdhq",
        "outputId": "ad473708-4662-49ee-ad9e-a35c0304498d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 421)\n"
          ]
        }
      ],
      "source": [
        "print(count_matrix.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpjCz58UI62D"
      },
      "source": [
        "#### 2: Building Cosine Similarity Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "M3rn6GT_RUIh"
      },
      "outputs": [],
      "source": [
        "## We build it as an pyarrow dataframe because it is the most efficient \n",
        "table = pa.Table.from_pandas(pd.DataFrame(cosine_similarity(count_matrix, count_matrix)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BLBAThCiQ7u"
      },
      "source": [
        "## Model & Data Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "0lSgay2QBLfR"
      },
      "outputs": [],
      "source": [
        "## save the Master Dataset\n",
        "master_dataset.to_parquet('backend/assets/content/movie_database.parquet',engine='fastparquet',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KoXEYlfldl1F"
      },
      "outputs": [],
      "source": [
        "## Writing the Matrix table\n",
        "pq.write_table(table, 'backend/assets/content/model.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e416IXE3RCYJ"
      },
      "source": [
        "## Inference\n",
        "\n",
        ">     Loading the trained model to execute Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QR7FWs_eF8mv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pyarrow as pa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xo0PYdBwFxRc"
      },
      "outputs": [],
      "source": [
        "master_dataset = pd.read_parquet('backend/assets/content/movie_database.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "P1CdagSLNpC8",
        "outputId": "5d19e7ac-1104-4b3d-b8f0-42ac341e50b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>release_date</th>\n",
              "      <th>title</th>\n",
              "      <th>main_director</th>\n",
              "      <th>soup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-06-17</td>\n",
              "      <td>Minions</td>\n",
              "      <td>Kyle Balda</td>\n",
              "      <td>assist aftercreditssting duringcreditssting ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-10-24</td>\n",
              "      <td>Big Hero 6</td>\n",
              "      <td>Chris Williams</td>\n",
              "      <td>brotherbrotherrelationship hero talent reveng ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-02-09</td>\n",
              "      <td>Deadpool</td>\n",
              "      <td>Tim Miller</td>\n",
              "      <td>antihero mercenari marvelcom superhero basedon...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  release_date       title   main_director  \\\n",
              "0   2015-06-17     Minions      Kyle Balda   \n",
              "1   2014-10-24  Big Hero 6  Chris Williams   \n",
              "2   2016-02-09    Deadpool      Tim Miller   \n",
              "\n",
              "                                                soup  \n",
              "0  assist aftercreditssting duringcreditssting ev...  \n",
              "1  brotherbrotherrelationship hero talent reveng ...  \n",
              "2  antihero mercenari marvelcom superhero basedon...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "master_dataset.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5sQlU1ujNBQt"
      },
      "outputs": [],
      "source": [
        "table = pa.parquet.read_table('backend/assets/content/model.parquet').to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z8YlkFPwEitp"
      },
      "outputs": [],
      "source": [
        "master_dataset = master_dataset.reset_index()\n",
        "titles = master_dataset['title']\n",
        "indices = pd.Series(master_dataset.index, index=master_dataset['title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "on_-itFvj-6x"
      },
      "outputs": [],
      "source": [
        "def get_recommendations(movie_id_from_db,movie_db):\n",
        "    try:\n",
        "        sim_scores = list(enumerate(movie_db[movie_id_from_db]))\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "        sim_scores = sim_scores[1:15] ## get top 15 Recommendations\n",
        "        \n",
        "        movie_indices = [i[0] for i in sim_scores]\n",
        "        output = master_dataset.iloc[movie_indices]\n",
        "        output.reset_index(inplace=True, drop=True)\n",
        "\n",
        "        response = []\n",
        "        for i in range(len(output)):\n",
        "            response.append({\n",
        "                'movie_title':output['title'].iloc[i],\n",
        "                'movie_release_date':output['release_date'].iloc[i],\n",
        "                'movie_director':output['main_director'].iloc[i],\n",
        "                'google_link':\"https://www.google.com/search?q=\" + '+'.join(output['title'].iloc[i].strip().split())\n",
        "            })\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"error: \",e)\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obiDKWO3kPQO",
        "outputId": "c5505e5f-1d1d-445d-e873-d3be67c90e6f"
      },
      "outputs": [],
      "source": [
        "movie_name = input('Enter a movie Name: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "print(titles.to_list().index('Minions'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lmp4yv5CFgw6"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "'big' is not in list",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m movie_index \u001b[38;5;241m=\u001b[39m \u001b[43mtitles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovie_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m get_recommendations(movie_index,table)\n",
            "\u001b[1;31mValueError\u001b[0m: 'big' is not in list"
          ]
        }
      ],
      "source": [
        "movie_index = titles.to_list().index(movie_name)\n",
        "recommendations = get_recommendations(movie_index,table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIr4jsTWGap5",
        "outputId": "70cb630a-a61d-4ad5-86ca-efbf0db5e0c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie Title                                   | Director             | Release Date   \n",
            "--------------------------------------------------------------------------------\n",
            "Minions                                       | Kyle Balda           | 2015-06-17     \n",
            "Monsters, Inc.                                | Pete Docter          | 2001-11-01     \n",
            "Ted 2                                         | Seth MacFarlane      | 2015-06-25     \n",
            "Finding Nemo                                  | Andrew Stanton       | 2003-05-30     \n",
            "Fantastic Beasts and Where to Find Them       | David Yates          | 2016-11-16     \n",
            "Deadpool                                      | Tim Miller           | 2016-02-09     \n",
            "Spirited Away                                 | Hayao Miyazaki       | 2001-07-20     \n",
            "Sex Tape                                      | Jake Kasdan          | 2014-07-17     \n",
            "Furious 7                                     | James Wan            | 2015-04-01     \n",
            "Pirates of the Caribbean: On Stranger Tides   | Rob Marshall         | 2011-05-14     \n",
            "Ant-Man                                       | Peyton Reed          | 2015-07-14     \n",
            "Kingsman: The Secret Service                  | Matthew Vaughn       | 2015-01-29     \n",
            "Star Wars: The Force Awakens                  | J.J. Abrams          | 2015-12-15     \n",
            "Thor                                          | Kenneth Branagh      | 2011-04-21     \n"
          ]
        }
      ],
      "source": [
        "print(f\"{'Movie Title':<45} | {'Director':<20} | {'Release Date':<15}\")\n",
        "print(f\"-\"*80)\n",
        "for recommendation in recommendations:\n",
        "    print(f\"{recommendation['movie_title']:<45} | {recommendation['movie_director']:<20} | {recommendation['movie_release_date']:<15}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "gpu_env",
      "language": "python",
      "name": "gpu_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
